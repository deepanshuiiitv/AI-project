{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ff3d6a",
   "metadata": {},
   "source": [
    "# TinyImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, zipfile, urllib.request\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746c768",
   "metadata": {},
   "source": [
    "1 Download TinyImageNet Subset (if not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./TinyImageNet\"\n",
    "zip_path = os.path.join(data_root, \"tiny-imagenet-200.zip\")\n",
    "extract_path = os.path.join(data_root, \"tiny-imagenet-200\")\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(data_root, exist_ok=True)\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    print(\" Downloading TinyImageNet (~250MB)...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print(\" Extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_root)\n",
    "    print(\" Done.\")\n",
    "else:\n",
    "    print(\" TinyImageNet already available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353688a0",
   "metadata": {},
   "source": [
    "2 Strong NUI Mask Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ba769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strong_nui_mask(h, w, strength=1.0, exponent=2.0):\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')\n",
    "    angle = np.random.uniform(0, 2*np.pi)\n",
    "    direction = np.cos(angle)*xx + np.sin(angle)*yy\n",
    "    cx, cy = np.random.uniform(-0.5, 0.5, 2)\n",
    "    r = np.sqrt((xx - cx)**2 + (yy - cy)**2)\n",
    "    radial = 1 - np.clip(r, 0, 1)**exponent\n",
    "    mask = 0.6*direction + 0.4*radial\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "    mask = 1 + strength * (mask - 0.5)\n",
    "    mask = np.clip(mask, 0.1, 1.9).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_tensor(img_tensor, mask):\n",
    "    mask = torch.tensor(mask).unsqueeze(0)\n",
    "    if img_tensor.shape[1:] != mask.shape[1:]:\n",
    "        mask = torch.nn.functional.interpolate(\n",
    "            mask.unsqueeze(0), size=img_tensor.shape[1:], mode='bilinear', align_corners=False\n",
    "        ).squeeze(0)\n",
    "    return img_tensor * mask\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b6a2b",
   "metadata": {},
   "source": [
    "3 Load TinyImageNet Subset (5 classes only, fixed labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset_path = os.path.join(extract_path, \"train\")\n",
    "full_dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "print(\"Total TinyImageNet train samples:\", len(full_dataset))\n",
    "\n",
    "# Pick 8 random classes\n",
    "class_indices = random.sample(range(200), 8)\n",
    "print(\"Selected class indices:\", class_indices)\n",
    "\n",
    "#  Build class mapping (old â†’ new)\n",
    "label_map = {old: new for new, old in enumerate(class_indices)}\n",
    "\n",
    "#  Filter dataset for only these classes\n",
    "subset_samples = [\n",
    "    (path, label_map[label]) for path, label in full_dataset.samples if label in class_indices\n",
    "]\n",
    "\n",
    "#  Replace samples and targets\n",
    "full_dataset.samples = subset_samples\n",
    "full_dataset.targets = [label for _, label in subset_samples]\n",
    "\n",
    "# Take subset of 2000 images\n",
    "subset_idx = list(range(min(2000, len(full_dataset.samples))))\n",
    "dataset = Subset(full_dataset, subset_idx)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "num_classes = len(class_indices)\n",
    "print(f\"Training samples: {len(trainset)} | Test samples: {len(testset)} | Classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4763b",
   "metadata": {},
   "source": [
    "4  Tiny CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        # Load pretrained SqueezeNet\n",
    "        self.model = models.squeezenet1_1(pretrained=False)\n",
    "        \n",
    "        # Replace the final classifier\n",
    "        self.model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.model.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d85bb6",
   "metadata": {},
   "source": [
    "5 Train & Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0517d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion, epochs=3, apply_nui=False):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for imgs, labels in tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if apply_nui:\n",
    "                imgs_aug = []\n",
    "                for img in imgs:\n",
    "                    if np.random.rand() < 0.7:\n",
    "                        mask = generate_strong_nui_mask(64, 64,\n",
    "                            strength=np.random.uniform(-3.0, 3.0),\n",
    "                            exponent=np.random.uniform(0.8, 3.5)\n",
    "                        )\n",
    "                        img = apply_mask_to_tensor(img, mask)\n",
    "                    imgs_aug.append(img)\n",
    "                imgs = torch.stack(imgs_aug)\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(imgs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "def evaluate(model, loader, apply_nui=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            if apply_nui:\n",
    "                imgs_aug = []\n",
    "                for img in imgs:\n",
    "                    mask = generate_strong_nui_mask(64, 64, strength=3.0, exponent=2.0)\n",
    "                    img = apply_mask_to_tensor(img, mask)\n",
    "                    imgs_aug.append(img)\n",
    "                imgs = torch.stack(imgs_aug)\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            _, predicted = model(imgs).max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54df73",
   "metadata": {},
   "source": [
    "6 Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_nui_effect(num_images=4):\n",
    "    imgs, _ = next(iter(testloader))\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(9, 9))\n",
    "    for i in range(num_images):\n",
    "        img = imgs[i]\n",
    "        mask = generate_strong_nui_mask(64, 64, strength=3.0, exponent=2.0)\n",
    "        img_nui = apply_mask_to_tensor(img, mask)\n",
    "        axes[i,0].imshow(img.permute(1,2,0)); axes[i,0].set_title(\"Original\"); axes[i,0].axis(\"off\")\n",
    "        axes[i,1].imshow(mask, cmap=\"gray\"); axes[i,1].set_title(\"Mask\"); axes[i,1].axis(\"off\")\n",
    "        axes[i,2].imshow(img_nui.permute(1,2,0)); axes[i,2].set_title(\"NUI Applied\"); axes[i,2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize few samples\n",
    "visualize_nui_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60186c88",
   "metadata": {},
   "source": [
    "7 Baseline vs Robust Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nui_to_img(img_tensor):\n",
    "    # img_tensor shape: (C, H, W)\n",
    "    h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
    "    mask = generate_strong_nui_mask(h, w)\n",
    "    return apply_mask_to_tensor(img_tensor, mask)\n",
    "\n",
    "def train_model_mixed(model, trainloader, optimizer, criterion, epochs, nui_ratio=0.2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Apply NUI to a random 20% of the batch\n",
    "            mask = torch.rand(len(imgs)) < nui_ratio\n",
    "            imgs_aug = []\n",
    "            for i, img in enumerate(imgs):\n",
    "                if mask[i]:\n",
    "                    imgs_aug.append(apply_nui_to_img(img))  # your NUI function\n",
    "                else:\n",
    "                    imgs_aug.append(img)\n",
    "            imgs_aug = torch.stack(imgs_aug)\n",
    "\n",
    "            # Forward, backward, optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs_aug)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f700a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Baseline Model\n",
    "model_clean = SqueezeNetCustom(num_classes).to(device)\n",
    "optimizer = optim.Adam(model_clean.parameters(), lr=0.001)\n",
    "print(\"\\n=== Training Baseline Model (Clean) ===\")\n",
    "train_model(model_clean, trainloader, optimizer, criterion, epochs=3, apply_nui=False)\n",
    "acc_clean = evaluate(model_clean, testloader, apply_nui=False)\n",
    "acc_nui = evaluate(model_clean, testloader, apply_nui=True)\n",
    "print(f\"\\nBefore Robust Training:\\nClean: {acc_clean*100:.2f}% | NUI: {acc_nui*100:.2f}%\")\n",
    "\n",
    "# NUI-Augmented Model\n",
    "model_nui = SqueezeNetCustom(num_classes).to(device)\n",
    "optimizer = optim.Adam(model_nui.parameters(), lr=0.001)\n",
    "print(\"\\n=== Training Robust Model (NUI-Augmented) ===\")\n",
    "train_model_mixed(model_nui, trainloader, optimizer, criterion, epochs=3, nui_ratio=0.8)\n",
    "acc_clean_aug = evaluate(model_nui, testloader, apply_nui=False)\n",
    "acc_nui_aug = evaluate(model_nui, testloader, apply_nui=True)\n",
    "print(f\"\\nAfter NUI-Augmented Training:\\nClean: {acc_clean_aug*100:.2f}% | NUI: {acc_nui_aug*100:.2f}%\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Accuracy Drop Before: {abs(acc_clean - acc_nui)*100:.2f}%\")\n",
    "print(f\"Accuracy Drop After:  {abs(acc_clean_aug - acc_nui_aug)*100:.2f}%\")\n",
    "drop_before = abs(acc_clean - acc_nui)*100\n",
    "drop_after = abs(acc_clean_aug - acc_nui_aug)*100\n",
    "improvement = drop_before - drop_after\n",
    "print(f\"   NUI Robustness Improvement: {improvement:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
