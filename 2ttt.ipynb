{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "TinyImageNet already available.\n",
      "Total TinyImageNet train samples: 100000\n",
      "Selected class indices: [104, 13, 192, 196, 55, 116, 47, 94]\n",
      "Training samples: 1600 | Test samples: 400 | Classes: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 1/3: 100%|██████████| 25/25 [00:17<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 2/3: 100%|██████████| 25/25 [00:11<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 3/3: 100%|██████████| 25/25 [00:10<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1604\n",
      "Baseline training done.\n",
      "\n",
      "Epoch 1/3 Loss: 1.5107\n",
      "Epoch 2/3 Loss: 1.2477\n",
      "Epoch 3/3 Loss: 1.1038\n",
      "NUI-Augmented robust training complete.\n",
      "\n",
      "Baseline Model:\n",
      "  Clean Test Accuracy: 58.50%\n",
      "  NUI Test Accuracy:   55.50%\n",
      "  Accuracy Drop:       3.00%\n",
      "\n",
      "Robust Model (NUI-Augmented Training):\n",
      "  Clean Test Accuracy: 58.50%\n",
      "  NUI Test Accuracy:   58.25%\n",
      "  Accuracy Increase on NUI: 2.75%\n",
      "  Accuracy Drop (after augmentation): 0.25%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1 Setup\n",
    "# ==============================================\n",
    "import os, random, zipfile, urllib.request\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ==============================================\n",
    "# 2 Download TinyImageNet Subset (if not present)\n",
    "# ==============================================\n",
    "data_root = \"./TinyImageNet\"\n",
    "zip_path = os.path.join(data_root, \"tiny-imagenet-200.zip\")\n",
    "extract_path = os.path.join(data_root, \"tiny-imagenet-200\")\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(data_root, exist_ok=True)\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    print(\"Downloading TinyImageNet (~250MB)...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_root)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"TinyImageNet already available.\")\n",
    "\n",
    "# ==============================================\n",
    "# 3 Strong NUI Mask Functions\n",
    "# ==============================================\n",
    "def generate_strong_nui_mask(h, w, strength=1.0, exponent=2.0):\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')\n",
    "    angle = np.random.uniform(0, 2*np.pi)\n",
    "    direction = np.cos(angle)*xx + np.sin(angle)*yy\n",
    "    cx, cy = np.random.uniform(-0.5, 0.5, 2)\n",
    "    r = np.sqrt((xx - cx)**2 + (yy - cy)**2)\n",
    "    radial = 1 - np.clip(r, 0, 1)**exponent\n",
    "    mask = 0.6*direction + 0.4*radial\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "    mask = 1 + strength * (mask - 0.5)\n",
    "    mask = np.clip(mask, 0.1, 1.9).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_tensor(img_tensor, mask):\n",
    "    mask_tensor = torch.tensor(mask).unsqueeze(0).to(img_tensor.device)\n",
    "    if mask_tensor.dim() == 3:\n",
    "        mask_tensor = mask_tensor.unsqueeze(0)\n",
    "    mask_tensor = F.interpolate(mask_tensor, size=img_tensor.shape[1:], mode='bilinear', align_corners=False).squeeze(0)\n",
    "    return img_tensor * mask_tensor\n",
    "\n",
    "def apply_nui_to_img(img_tensor):\n",
    "    h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
    "    mask = generate_strong_nui_mask(h, w)\n",
    "    return apply_mask_to_tensor(img_tensor, mask)\n",
    "\n",
    "# ==============================================\n",
    "# 4 Load TinyImageNet Subset (8 Classes)\n",
    "# ==============================================\n",
    "transform = T.Compose([T.Resize((64, 64)), T.ToTensor()])\n",
    "\n",
    "dataset_path = os.path.join(extract_path, \"train\")\n",
    "full_dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "print(\"Total TinyImageNet train samples:\", len(full_dataset))\n",
    "\n",
    "# Pick 8 random classes\n",
    "class_indices = random.sample(range(200), 8)\n",
    "print(\"Selected class indices:\", class_indices)\n",
    "\n",
    "# Build label mapping (old -> new)\n",
    "label_map = {old: new for new, old in enumerate(class_indices)}\n",
    "\n",
    "# Filter dataset for only these classes\n",
    "subset_samples = [(path, label_map[label]) for path, label in full_dataset.samples if label in class_indices]\n",
    "\n",
    "# Replace samples and targets\n",
    "full_dataset.samples = subset_samples\n",
    "full_dataset.targets = [label for _, label in subset_samples]\n",
    "\n",
    "# Take subset of 2000 images\n",
    "subset_idx = list(range(min(2000, len(full_dataset.samples))))\n",
    "dataset = Subset(full_dataset, subset_idx)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader  = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "num_classes = len(class_indices)\n",
    "print(f\"Training samples: {len(trainset)} | Test samples: {len(testset)} | Classes: {num_classes}\")\n",
    "\n",
    "# ==============================================\n",
    "# 5 Tiny CNN Model (SqueezeNet)\n",
    "# ==============================================\n",
    "import torchvision.models as models\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.model = models.squeezenet1_1(pretrained=False)\n",
    "        self.model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.model.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ==============================================\n",
    "# 6 Evaluation Function\n",
    "# ==============================================\n",
    "def testing(model, loader, apply_nui=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            if apply_nui:\n",
    "                perturbed = [apply_nui_to_img(img) for img in imgs]\n",
    "                imgs = torch.stack(perturbed)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# ==============================================\n",
    "# 7 Baseline Training (Clean Images)\n",
    "# ==============================================\n",
    "model_clean = SqueezeNetCustom(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_clean.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model_clean.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in tqdm(trainloader, desc=f\"Baseline Epoch {epoch+1}/{epochs}\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_clean(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss: {running_loss/len(trainloader):.4f}\")\n",
    "print(\"Baseline training done.\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 8 NUI-Augmented (Robust) Training\n",
    "# ==============================================\n",
    "def train_model_mixed(model, trainloader, optimizer, criterion, epochs, nui_ratio=0.8):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            mask = torch.rand(len(imgs)) < nui_ratio\n",
    "            imgs_aug = [apply_nui_to_img(img) if mask[i] else img for i, img in enumerate(imgs)]\n",
    "            imgs_aug = torch.stack(imgs_aug)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs_aug)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "# Train robust model\n",
    "model_nui = SqueezeNetCustom(num_classes=num_classes).to(device)\n",
    "optimizer = optim.Adam(model_nui.parameters(), lr=0.001)\n",
    "train_model_mixed(model_nui, trainloader, optimizer, criterion, epochs, nui_ratio=0.8)\n",
    "print(\"NUI-Augmented robust training complete.\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 9 Evaluate Models\n",
    "# ==============================================\n",
    "acc_clean     = testing(model_clean, testloader, apply_nui=False)\n",
    "acc_nui       = testing(model_clean, testloader, apply_nui=True)\n",
    "acc_clean_aug = testing(model_nui, testloader, apply_nui=False)\n",
    "acc_nui_aug   = testing(model_nui, testloader, apply_nui=True)\n",
    "\n",
    "# Convert to percentage\n",
    "acc_clean_pct     = acc_clean * 100\n",
    "acc_nui_pct       = acc_nui * 100\n",
    "acc_clean_aug_pct = acc_clean_aug * 100\n",
    "acc_nui_aug_pct   = acc_nui_aug * 100\n",
    "\n",
    "# Baseline model (trained on clean data)\n",
    "acc_clean_drop = acc_clean_pct - acc_nui_pct\n",
    "print(f\"Baseline Model:\")\n",
    "print(f\"  Clean Test Accuracy: {acc_clean_pct:.2f}%\")\n",
    "print(f\"  NUI Test Accuracy:   {acc_nui_pct:.2f}%\")\n",
    "print(f\"  Accuracy Drop:       {acc_clean_drop:.2f}%\\n\")\n",
    "\n",
    "# Robust model (trained on NUI-augmented data)\n",
    "acc_nui_increase = acc_nui_aug_pct - acc_nui_pct\n",
    "robust_drop = acc_clean_aug_pct - acc_nui_aug_pct\n",
    "\n",
    "print(f\"Robust Model (NUI-Augmented Training):\")\n",
    "print(f\"  Clean Test Accuracy: {acc_clean_aug_pct:.2f}%\")\n",
    "print(f\"  NUI Test Accuracy:   {acc_nui_aug_pct:.2f}%\")\n",
    "print(f\"  Accuracy Increase on NUI: {acc_nui_increase:.2f}%\")\n",
    "\n",
    "# ==============================================\n",
    "# 10 Visualize NUI Effect\n",
    "# ==============================================\n",
    "def visualize_nui_effect(num_images=4):\n",
    "    imgs, _ = next(iter(testloader))\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(9, 9))\n",
    "    for i in range(num_images):\n",
    "        img = imgs[i]\n",
    "        mask = generate_strong_nui_mask(64, 64, strength=3.0, exponent=2.0)\n",
    "        img_nui = apply_mask_to_tensor(img, mask)\n",
    "        axes[i,0].imshow(img.permute(1,2,0)); axes[i,0].set_title(\"Original\"); axes[i,0].axis(\"off\")\n",
    "        axes[i,1].imshow(mask, cmap=\"gray\"); axes[i,1].set_title(\"Mask\"); axes[i,1].axis(\"off\")\n",
    "        axes[i,2].imshow(img_nui.permute(1,2,0)); axes[i,2].set_title(\"NUI Applied\"); axes[i,2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_nui_effect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
