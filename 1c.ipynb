{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b529dd2e",
   "metadata": {},
   "source": [
    "###  Miniature Non-Uniform Illumination (NUI) Robustness Project\n",
    "### CIFAR-10 (Cats vs Dogs) – Clear 20–30% Accuracy Gap Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c087654",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569e9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n",
      "Torch: 2.9.0+cpu\n",
      "Torchvision: 0.24.0+cpu\n",
      "NumPy: 2.2.6\n",
      "Matplotlib: 3.8.4\n",
      "TQDM: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n",
    "print(\"TQDM:\", tqdm.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2bd89",
   "metadata": {},
   "source": [
    "1 Non-Uniform Illumination (NUI) Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strong_nui_mask(h, w, strength=3.0, exponent=2.0):\n",
    "    \"\"\"\n",
    "    Generate a strong directional uneven illumination mask.\n",
    "    h, w: height and width\n",
    "    strength: how strong the illumination change is\n",
    "    exponent: controls the gradient sharpness\n",
    "    \"\"\"\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')\n",
    "    angle = np.random.uniform(0, np.pi)\n",
    "    grad = np.cos(angle) * xx + np.sin(angle) * yy\n",
    "    grad = (grad - grad.min()) / (grad.max() - grad.min())  # normalize 0-1\n",
    "    mask = grad ** exponent\n",
    "    mask = 1 + strength * (mask - 0.5)                     # apply strong modulation\n",
    "    mask = np.clip(mask, 0, 2).astype(np.float32)          # clip extreme values\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_tensor(img_tensor, mask):\n",
    "    \"\"\"\n",
    "    Apply a NUI mask to a PyTorch image tensor\n",
    "    \"\"\"\n",
    "    mask_tensor = torch.tensor(mask).unsqueeze(0)\n",
    "    if mask_tensor.dim() == 3:\n",
    "        mask_tensor = mask_tensor.unsqueeze(0)\n",
    "    mask_tensor = torch.nn.functional.interpolate(\n",
    "        mask_tensor,\n",
    "        size=img_tensor.shape[1:],\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    ).squeeze(0)\n",
    "    return img_tensor * mask_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ced45",
   "metadata": {},
   "source": [
    "2 Load CIFAR-10 Small Subset (Cats vs Dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "trainset_full = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset_full  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "classes_to_use = [3, 5]  # cat=3, dog=5\n",
    "train_idx = [i for i, t in enumerate(trainset_full.targets) if t in classes_to_use][:3000]\n",
    "test_idx  = [i for i, t in enumerate(testset_full.targets) if t in classes_to_use][:400]\n",
    "\n",
    "trainset = Subset(trainset_full, train_idx)\n",
    "testset  = Subset(testset_full, test_idx)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader  = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(trainset)} | Test samples: {len(testset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44138cd8",
   "metadata": {},
   "source": [
    "3 Tiny CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        # Load pretrained SqueezeNet\n",
    "        self.model = models.squeezenet1_1(pretrained=False)\n",
    "        \n",
    "        # Replace the final classifier\n",
    "        self.model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.model.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9e463",
   "metadata": {},
   "source": [
    "4 Train on Clean Images (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ad6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SqueezeNetCustom(num_classes=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 6\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = torch.tensor([classes_to_use.index(l.item()) for l in labels]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss: {running_loss/len(trainloader):.4f}\")\n",
    "print(\" Baseline training done.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907310b",
   "metadata": {},
   "source": [
    "5 Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, apply_nui=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            labels = torch.tensor([classes_to_use.index(l.item()) for l in labels]).to(device)\n",
    "            if apply_nui:\n",
    "                perturbed = []\n",
    "                for img in imgs:\n",
    "                    mask = generate_strong_nui_mask(\n",
    "                        32, 32,\n",
    "                        strength=np.random.uniform(-2.0, 2.0),\n",
    "                        exponent=np.random.uniform(1.2, 4.0)\n",
    "                    )\n",
    "                    pert = apply_mask_to_tensor(img, mask)\n",
    "                    perturbed.append(pert)\n",
    "                imgs = torch.stack(perturbed)\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f5a6b",
   "metadata": {},
   "source": [
    "6 Baseline Evaluation (Expect ~25% drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474600a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean = evaluate(model, testloader, apply_nui=False)\n",
    "acc_nui   = evaluate(model, testloader, apply_nui=True)\n",
    "\n",
    "print(\"Before Robust Training:\")\n",
    "print(f\"Clean test accuracy: {acc_clean*100:.2f}%\")\n",
    "print(f\"NUI test accuracy:   {acc_nui*100:.2f}%\")\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19c992",
   "metadata": {},
   "source": [
    "7 NUI-Augmented (Robust) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nui_to_img(img_tensor):\n",
    "    # img_tensor shape: (C, H, W)\n",
    "    h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
    "    mask = generate_strong_nui_mask(h, w)\n",
    "    return apply_mask_to_tensor(img_tensor, mask)\n",
    "\n",
    "def train_model_mixed(model, trainloader, optimizer, criterion, epochs, nui_ratio=0.2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Apply NUI to a random 20% of the batch\n",
    "            mask = torch.rand(len(imgs)) < nui_ratio\n",
    "            imgs_aug = []\n",
    "            for i, img in enumerate(imgs):\n",
    "                if mask[i]:\n",
    "                    imgs_aug.append(apply_nui_to_img(img))  # your NUI function\n",
    "                else:\n",
    "                    imgs_aug.append(img)\n",
    "            imgs_aug = torch.stack(imgs_aug)\n",
    "\n",
    "            # Forward, backward, optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs_aug)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nui = SqueezeNetCustom(num_classes=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_nui.parameters(), lr=0.001)\n",
    "train_model_mixed(model_nui, trainloader, optimizer, criterion, epochs=3, nui_ratio=0.8)\n",
    "print(\"NUI-Augmented robust training complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e8568",
   "metadata": {},
   "source": [
    "8 Evaluate Robust Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean_aug = evaluate(model_nui, testloader, apply_nui=False)\n",
    "acc_nui_aug   = evaluate(model_nui, testloader, apply_nui=True)\n",
    "\n",
    "print(\"After NUI-Augmented Training:\")\n",
    "print(f\"Clean test accuracy: {acc_clean_aug*100:.2f}%\")\n",
    "print(f\"NUI test accuracy:   {acc_nui_aug*100:.2f}%\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Accuracy Drop Before: {(acc_clean - acc_nui)*100:.2f}%\")\n",
    "print(f\"Accuracy Drop After:  {(acc_clean_aug - acc_nui_aug)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4483ba",
   "metadata": {},
   "source": [
    "9 Visualize Illumination Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single example with NUI mask\n",
    "imgs, _ = next(iter(testloader))\n",
    "mask = generate_strong_nui_mask(32, 32, strength=1.5, exponent=2.5)\n",
    "pert = apply_mask_to_tensor(imgs[0], mask)\n",
    "\n",
    "# Convert to numpy for display\n",
    "img_np  = np.transpose(imgs[0].numpy(), (1,2,0))\n",
    "mask_np = mask\n",
    "pert_np = np.transpose(pert.numpy(), (1,2,0))\n",
    "\n",
    "# Plot original, mask, and NUI-applied versions\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.clip(img_np, 0, 1))\n",
    "plt.title(\"Original\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(mask_np, cmap='hot', vmin=0, vmax=2)\n",
    "plt.title(\"Illumination Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(np.clip(pert_np, 0, 1))\n",
    "plt.title(\"Strong NUI Applied\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute robustness improvement\n",
    "drop_before = abs(acc_clean - acc_nui)*100\n",
    "drop_after = abs(acc_clean_aug - acc_nui_aug)*100\n",
    "improvement = drop_before - drop_after\n",
    "print(f\"   NUI Robustness Improvement: {improvement:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
