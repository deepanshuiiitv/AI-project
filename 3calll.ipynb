{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      " Total Caltech-256 samples: 30607\n",
      "Train: 839 | Test: 210 | Classes: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\college\\College_project\\AI_project\\Non-Uniform_Illumination\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "a:\\college\\College_project\\AI_project\\Non-Uniform_Illumination\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Baseline Epoch 1/3:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1 Setup\n",
    "# ==============================================\n",
    "import os, random, zipfile, urllib.request\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ==============================================\n",
    "# 2 Load Caltech-256 Dataset (Resized)\n",
    "# ==============================================\n",
    "data_root = \"./Caltech256\"\n",
    "\n",
    "# Ensure 3 channels\n",
    "def ensure_3_channel(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        if img.shape[0] == 1:\n",
    "            return img.repeat(3, 1, 1)\n",
    "        return img\n",
    "    else:\n",
    "        if img.mode != 'RGB':\n",
    "            return img.convert('RGB')\n",
    "        return img\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.Lambda(ensure_3_channel),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "try:\n",
    "    dataset_full = torchvision.datasets.Caltech256(\n",
    "        root=data_root,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    print(\" Total Caltech-256 samples:\", len(dataset_full))\n",
    "except:\n",
    "    class DummyCaltech256(torch.utils.data.Dataset):\n",
    "        def __init__(self, size=2000):\n",
    "            self.size = size\n",
    "        def __len__(self):\n",
    "            return self.size\n",
    "        def __getitem__(self, idx):\n",
    "            img = torch.rand(3, 64, 64)\n",
    "            label = random.randint(0, 9)\n",
    "            return img, label\n",
    "    dataset_full = DummyCaltech256()\n",
    "    print(\" Using dummy dataset with 2000 samples\")\n",
    "\n",
    "# ==============================================\n",
    "# 3 Strong NUI Mask Functions\n",
    "# ==============================================\n",
    "def generate_strong_nui_mask(h, w, strength=1.0, exponent=2.0):\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')\n",
    "    angle = np.random.uniform(0, 2*np.pi)\n",
    "    direction = np.cos(angle)*xx + np.sin(angle)*yy\n",
    "    cx, cy = np.random.uniform(-0.5, 0.5, 2)\n",
    "    r = np.sqrt((xx - cx)**2 + (yy - cy)**2)\n",
    "    radial = 1 - np.clip(r, 0, 1)**exponent\n",
    "    mask = 0.6*direction + 0.4*radial\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "    mask = 1 + strength * (mask - 0.5)\n",
    "    mask = np.clip(mask, 0.1, 1.9).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_tensor(img_tensor, mask):\n",
    "    mask_tensor = torch.tensor(mask).unsqueeze(0)\n",
    "    if mask_tensor.dim() == 3:\n",
    "        mask_tensor = mask_tensor.unsqueeze(0)\n",
    "    mask_tensor = F.interpolate(\n",
    "        mask_tensor,\n",
    "        size=img_tensor.shape[1:],\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    ).squeeze(0)\n",
    "    return img_tensor * mask_tensor\n",
    "\n",
    "def apply_nui_to_img(img_tensor):\n",
    "    h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
    "    mask = generate_strong_nui_mask(h, w)\n",
    "    return apply_mask_to_tensor(img_tensor, mask)\n",
    "\n",
    "# ==============================================\n",
    "# 4 Subset for Speed (10 Classes)\n",
    "# ==============================================\n",
    "num_classes_to_use = 10\n",
    "all_labels = []\n",
    "\n",
    "for i in range(min(1000, len(dataset_full))):\n",
    "    try:\n",
    "        _, label = dataset_full[i]\n",
    "        all_labels.append(label)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "unique_labels = list(set(all_labels))\n",
    "class_indices = random.sample(unique_labels, min(num_classes_to_use, len(unique_labels)))\n",
    "\n",
    "class SubsetCaltech256(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, class_indices):\n",
    "        self.dataset = dataset\n",
    "        self.class_map = {c:i for i, c in enumerate(class_indices)}\n",
    "        self.indices = [i for i, (_, lbl) in enumerate(dataset) if lbl in class_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        img, lbl = self.dataset[real_idx]\n",
    "        return img, self.class_map[lbl]\n",
    "\n",
    "dataset = SubsetCaltech256(dataset_full, class_indices)\n",
    "subset_size = min(2000, len(dataset))\n",
    "subset_indices = list(range(subset_size))\n",
    "random.shuffle(subset_indices)\n",
    "dataset = Subset(dataset, subset_indices)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader  = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "num_classes = len(class_indices)\n",
    "print(f\"Train: {len(trainset)} | Test: {len(testset)} | Classes: {num_classes}\")\n",
    "\n",
    "# ==============================================\n",
    "# 5 Tiny CNN Model (SqueezeNet)\n",
    "# ==============================================\n",
    "import torchvision.models as models\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = models.squeezenet1_1(pretrained=False)\n",
    "        self.model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.model.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ==============================================\n",
    "# 6 Evaluation Function\n",
    "# ==============================================\n",
    "def testing(model, loader, apply_nui=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            if apply_nui:\n",
    "                imgs = torch.stack([apply_nui_to_img(img) for img in imgs])\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# ==============================================\n",
    "# 7 Baseline Training (Clean)\n",
    "# ==============================================\n",
    "model_clean = SqueezeNetCustom(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_clean.parameters(), lr=0.001)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_clean.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in tqdm(trainloader, desc=f\"Baseline Epoch {epoch+1}/{epochs}\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_clean(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss: {running_loss/len(trainloader):.4f}\")\n",
    "print(\"Baseline training done.\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 8 NUI-Augmented Training (Robust)\n",
    "# ==============================================\n",
    "def train_model_mixed(model, trainloader, optimizer, criterion, epochs, nui_ratio=0.8):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            mask = torch.rand(len(imgs)) < nui_ratio\n",
    "            imgs_aug = [apply_nui_to_img(img) if mask[i] else img for i, img in enumerate(imgs)]\n",
    "            imgs_aug = torch.stack(imgs_aug)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs_aug)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "model_nui = SqueezeNetCustom(num_classes=num_classes).to(device)\n",
    "optimizer = optim.Adam(model_nui.parameters(), lr=0.001)\n",
    "train_model_mixed(model_nui, trainloader, optimizer, criterion, epochs, nui_ratio=0.8)\n",
    "print(\"NUI-Augmented robust training complete.\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 9 Evaluate Models\n",
    "# ==============================================\n",
    "acc_clean     = testing(model_clean, testloader, apply_nui=False)\n",
    "acc_nui       = testing(model_clean, testloader, apply_nui=True)\n",
    "acc_clean_aug = testing(model_nui, testloader, apply_nui=False)\n",
    "acc_nui_aug   = testing(model_nui, testloader, apply_nui=True)\n",
    "\n",
    "acc_clean_pct     = acc_clean * 100\n",
    "acc_nui_pct       = acc_nui * 100\n",
    "acc_clean_aug_pct = acc_clean_aug * 100\n",
    "acc_nui_aug_pct   = acc_nui_aug * 100\n",
    "\n",
    "acc_clean_drop = acc_clean_pct - acc_nui_pct\n",
    "print(f\"Baseline Model:\")\n",
    "print(f\"  Clean Test Accuracy: {acc_clean_pct:.2f}%\")\n",
    "print(f\"  NUI Test Accuracy:   {acc_nui_pct:.2f}%\")\n",
    "print(f\"  Accuracy Drop:       {acc_clean_drop:.2f}%\\n\")\n",
    "\n",
    "acc_nui_increase = acc_nui_aug_pct - acc_nui_pct\n",
    "robust_drop = acc_clean_aug_pct - acc_nui_aug_pct\n",
    "\n",
    "print(f\"Robust Model (NUI-Augmented Training):\")\n",
    "print(f\"  Clean Test Accuracy: {acc_clean_aug_pct:.2f}%\")\n",
    "print(f\"  NUI Test Accuracy:   {acc_nui_aug_pct:.2f}%\")\n",
    "print(f\"  Accuracy Increase on NUI: {acc_nui_increase:.2f}%\")\n",
    "\n",
    "# ==============================================\n",
    "# 10 Visualize NUI Effect\n",
    "# ==============================================\n",
    "# def visualize_nui_effect(num_images=4):\n",
    "#     imgs, _ = next(iter(testloader))\n",
    "#     fig, axes = plt.subplots(num_images, 3, figsize=(9, 3*num_images))\n",
    "#     for i in range(num_images):\n",
    "#         img = imgs[i]\n",
    "#         mask = generate_strong_nui_mask(64, 64, strength=3.0, exponent=2.0)\n",
    "#         img_nui = apply_mask_to_tensor(img, mask)\n",
    "#         axes[i,0].imshow(img.permute(1,2,0)); axes[i,0].set_title(\"Original\"); axes[i,0].axis(\"off\")\n",
    "#         axes[i,1].imshow(mask, cmap=\"gray\"); axes[i,1].set_title(\"Mask\"); axes[i,1].axis(\"off\")\n",
    "#         axes[i,2].imshow(img_nui.permute(1,2,0)); axes[i,2].set_title(\"NUI Applied\"); axes[i,2].axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#\n",
    "# visualize_nui_effect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
