{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23495418",
   "metadata": {},
   "source": [
    "Non-Uniform Illumination Robustness — Caltech-256 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe53e4",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00219339",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1b35b",
   "metadata": {},
   "source": [
    "1. Load Caltech-256 (Resized to 64×64) - FIXED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea748ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./Caltech256\"\n",
    "\n",
    "# FIX: Better transformation that ensures 3 channels\n",
    "def ensure_3_channel(img):\n",
    "    \"\"\"Convert image to 3 channels if it's grayscale\"\"\"\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        if img.shape[0] == 1:\n",
    "            return img.repeat(3, 1, 1)\n",
    "        return img\n",
    "    else:  # PIL Image\n",
    "        if img.mode != 'RGB':\n",
    "            return img.convert('RGB')\n",
    "        return img\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.Lambda(ensure_3_channel),  # Ensure 3 channels\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "try:\n",
    "    dataset_full = torchvision.datasets.Caltech256(\n",
    "        root=data_root,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    print(\" Total Caltech-256 samples:\", len(dataset_full))\n",
    "except Exception as e:\n",
    "    print(f\" Error loading dataset: {e}\")\n",
    "    print(\" Creating a dummy dataset for demonstration...\")\n",
    "    # Create dummy dataset as fallback\n",
    "    from torch.utils.data import Dataset\n",
    "    class DummyCaltech256(Dataset):\n",
    "        def __init__(self, size=1000, transform=None):\n",
    "            self.size = size\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.size\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            img = torch.rand(3, 64, 64)  # Always 3 channels\n",
    "            label = random.randint(0, 9)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "    \n",
    "    dataset_full = DummyCaltech256(size=2000, transform=transform)\n",
    "    print(\" Created dummy dataset with\", len(dataset_full), \"samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a658b0d",
   "metadata": {},
   "source": [
    "2️ Strong NUI Mask Generator (High Penetration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strong_nui_mask(h, w, strength=1.0, exponent=2.0):\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')\n",
    "    angle = np.random.uniform(0, 2*np.pi)\n",
    "    direction = np.cos(angle)*xx + np.sin(angle)*yy\n",
    "    cx, cy = np.random.uniform(-0.5, 0.5, 2)\n",
    "    r = np.sqrt((xx - cx)**2 + (yy - cy)**2)\n",
    "    radial = 1 - np.clip(r, 0, 1)**exponent\n",
    "    mask = 0.6*direction + 0.4*radial\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "    mask = 1 + strength * (mask - 0.5)\n",
    "    mask = np.clip(mask, 0.1, 1.9).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_tensor(img_tensor, mask):\n",
    "    mask_tensor = torch.tensor(mask).unsqueeze(0)\n",
    "    if mask_tensor.dim() == 3:\n",
    "        mask_tensor = mask_tensor.unsqueeze(0)\n",
    "    mask_tensor = torch.nn.functional.interpolate(\n",
    "        mask_tensor,\n",
    "        size=img_tensor.shape[1:],\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    ).squeeze(0)\n",
    "    return img_tensor * mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f21830",
   "metadata": {},
   "source": [
    "3 Use Subset of Classes for Speed - FIXED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094701b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_to_use = 10\n",
    "\n",
    "# FIX: Create a custom dataset that ensures consistent channels\n",
    "class ConsistentChannelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_dataset, class_indices):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.class_indices = class_indices\n",
    "        self.indices = []\n",
    "        self.labels_map = {cls_idx: i for i, cls_idx in enumerate(class_indices)}\n",
    "        \n",
    "        # Collect indices of samples with 3 channels\n",
    "        for i in range(len(original_dataset)):\n",
    "            try:\n",
    "                img, label = original_dataset[i]\n",
    "                if label in class_indices and img.shape[0] == 3:\n",
    "                    self.indices.append(i)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.indices[idx]\n",
    "        img, label = self.original_dataset[original_idx]\n",
    "        # Remap label to 0-based indexing\n",
    "        new_label = self.labels_map[label]\n",
    "        return img, new_label\n",
    "\n",
    "try:\n",
    "    # Get all unique labels from the dataset\n",
    "    all_labels = []\n",
    "    for i in range(min(1000, len(dataset_full))):\n",
    "        try:\n",
    "            _, label = dataset_full[i]\n",
    "            all_labels.append(label)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    unique_labels = list(set(all_labels))\n",
    "    print(f\" Found {len(unique_labels)} unique labels in dataset sample\")\n",
    "    \n",
    "    # Select classes to use\n",
    "    class_indices = random.sample(unique_labels, min(num_classes_to_use, len(unique_labels)))\n",
    "    print(\" Selected class indices:\", class_indices)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error analyzing dataset: {e}\")\n",
    "    print(\" Using default class range...\")\n",
    "    class_indices = list(range(num_classes_to_use))\n",
    "\n",
    "# Create consistent dataset\n",
    "consistent_dataset = ConsistentChannelDataset(dataset_full, class_indices)\n",
    "print(f\" Found {len(consistent_dataset)} consistent samples in selected classes\")\n",
    "\n",
    "# Ensure we have enough samples\n",
    "if len(consistent_dataset) < 100:\n",
    "    print(\"  Not enough consistent samples, creating synthetic dataset...\")\n",
    "    # Fallback to synthetic data\n",
    "    from torch.utils.data import Dataset\n",
    "    class SyntheticCaltech256(Dataset):\n",
    "        def __init__(self, size=1000, num_classes=10):\n",
    "            self.size = size\n",
    "            self.num_classes = num_classes\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.size\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            img = torch.rand(3, 64, 64)  # Always 3 channels\n",
    "            label = random.randint(0, self.num_classes - 1)\n",
    "            return img, label\n",
    "    \n",
    "    consistent_dataset = SyntheticCaltech256(size=1000, num_classes=num_classes_to_use)\n",
    "    print(\" Created synthetic dataset with 1000 samples\")\n",
    "\n",
    "# Use subset for speed\n",
    "subset_size = min(1000, len(consistent_dataset))\n",
    "subset_indices = list(range(subset_size))\n",
    "random.shuffle(subset_indices)\n",
    "\n",
    "dataset = Subset(consistent_dataset, subset_indices)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "num_classes = len(class_indices)\n",
    "print(f\" Train: {len(trainset)} | Test: {len(testset)} | Classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ba8e3",
   "metadata": {},
   "source": [
    "4 CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        # Load pretrained SqueezeNet\n",
    "        self.model = models.squeezenet1_1(pretrained=False)\n",
    "        \n",
    "        # Replace the final classifier\n",
    "        self.model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.model.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29010717",
   "metadata": {},
   "source": [
    "5 Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa102a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion, epochs=3, apply_nui=False):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_batches = 0, 0\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_idx, (imgs, labels) in enumerate(pbar):\n",
    "            try:\n",
    "                if apply_nui:\n",
    "                    imgs_aug = []\n",
    "                    for img in imgs:\n",
    "                        if np.random.rand() < 0.7:  # 70% chance to apply NUI\n",
    "                            mask = generate_strong_nui_mask(\n",
    "                                img.shape[1], img.shape[2],\n",
    "                                strength=np.random.uniform(2.0, 4.0),\n",
    "                                exponent=np.random.uniform(1.0, 3.0)\n",
    "                            )\n",
    "                            img = apply_mask_to_tensor(img, mask)\n",
    "                        imgs_aug.append(img)\n",
    "                    imgs = torch.stack(imgs_aug)\n",
    "                \n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_batches += 1\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            except Exception as e:\n",
    "                print(f\"  Skipping batch {batch_idx} due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if total_batches > 0:\n",
    "            avg_loss = total_loss / total_batches\n",
    "            print(f\" Epoch {epoch+1}: Avg Loss = {avg_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\" Epoch {epoch+1}: No valid batches processed\")\n",
    "\n",
    "def evaluate(model, loader, apply_nui=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, labels) in enumerate(loader):\n",
    "            try:\n",
    "                if apply_nui:\n",
    "                    imgs_aug = []\n",
    "                    for img in imgs:\n",
    "                        mask = generate_strong_nui_mask(img.shape[1], img.shape[2], strength=3.5, exponent=2.0)\n",
    "                        img = apply_mask_to_tensor(img, mask)\n",
    "                        imgs_aug.append(img)\n",
    "                    imgs = torch.stack(imgs_aug)\n",
    "                \n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "            except Exception as e:\n",
    "                print(f\" Skipping evaluation batch {batch_idx} due to error: {e}\")\n",
    "                continue\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b56ce6",
   "metadata": {},
   "source": [
    "6 Visualization of NUI Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a495af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_nui_effect(num_images=4):\n",
    "    try:\n",
    "        sample_loader = DataLoader(testset, batch_size=num_images, shuffle=True, num_workers=0)\n",
    "        imgs, labels = next(iter(sample_loader))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_images, 3, figsize=(9, 3*num_images))\n",
    "        if num_images == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img = imgs[i]\n",
    "            mask = generate_strong_nui_mask(img.shape[1], img.shape[2], strength=3.5, exponent=2.0)\n",
    "            img_nui = apply_mask_to_tensor(img, mask)\n",
    "            \n",
    "            # Clamp values for display\n",
    "            img_display = torch.clamp(img.permute(1, 2, 0), 0, 1)\n",
    "            img_nui_display = torch.clamp(img_nui.permute(1, 2, 0), 0, 1)\n",
    "            \n",
    "            axes[i, 0].imshow(img_display)\n",
    "            axes[i, 0].set_title(\"Original\")\n",
    "            axes[i, 0].axis(\"off\")\n",
    "            \n",
    "            axes[i, 1].imshow(mask, cmap=\"hot\", vmin=0, vmax=2)\n",
    "            axes[i, 1].set_title(\"Illumination Mask\")\n",
    "            axes[i, 1].axis(\"off\")\n",
    "            \n",
    "            axes[i, 2].imshow(img_nui_display)\n",
    "            axes[i, 2].set_title(\"With NUI\")\n",
    "            axes[i, 2].axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\" Visualization error: {e}\")\n",
    "\n",
    "# Call visualization\n",
    "print(\"\\nVisualizing NUI Effect...\")\n",
    "visualize_nui_effect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400807be",
   "metadata": {},
   "source": [
    "7 Baseline vs NUI-Augmented Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nui_to_img(img_tensor):\n",
    "    # img_tensor shape: (C, H, W)\n",
    "    h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
    "    mask = generate_strong_nui_mask(h, w)\n",
    "    return apply_mask_to_tensor(img_tensor, mask)\n",
    "\n",
    "def train_model_mixed(model, trainloader, optimizer, criterion, epochs, nui_ratio=0.2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Apply NUI to a random 20% of the batch\n",
    "            mask = torch.rand(len(imgs)) < nui_ratio\n",
    "            imgs_aug = []\n",
    "            for i, img in enumerate(imgs):\n",
    "                if mask[i]:\n",
    "                    imgs_aug.append(apply_nui_to_img(img))  #  NUI function\n",
    "                else:\n",
    "                    imgs_aug.append(img)\n",
    "            imgs_aug = torch.stack(imgs_aug)\n",
    "\n",
    "            # Forward, backward, optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs_aug)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ffad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" STARTING EXPERIMENT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- Baseline Model ---\n",
    "print(\"\\n=== Training Baseline Model (Clean) ===\")\n",
    "model_clean = SqueezeNetCustom(num_classes).to(device)\n",
    "optimizer_clean = optim.Adam(model_clean.parameters(), lr=0.001)\n",
    "train_model(model_clean, trainloader, optimizer_clean, criterion, epochs=3, apply_nui=False)\n",
    "\n",
    "# Evaluate baseline\n",
    "acc_clean_clean = evaluate(model_clean, testloader, apply_nui=False)\n",
    "acc_clean_nui = evaluate(model_clean, testloader, apply_nui=True)\n",
    "\n",
    "print(f\" Baseline Model - Clean: {acc_clean_clean*100:.2f}% | NUI: {acc_clean_nui*100:.2f}%\")\n",
    "\n",
    "# --- NUI-Augmented Model ---\n",
    "print(\"\\n=== Training Robust Model (NUI-Augmented) ===\")\n",
    "model_nui = SqueezeNetCustom(num_classes).to(device)\n",
    "optimizer_nui = optim.Adam(model_nui.parameters(), lr=0.001)\n",
    "train_model_mixed(model_nui, trainloader, optimizer_clean, criterion, epochs=3, nui_ratio=0.8)\n",
    "\n",
    "# Evaluate robust model\n",
    "acc_nui_clean = evaluate(model_nui, testloader, apply_nui=False)\n",
    "acc_nui_nui = evaluate(model_nui, testloader, apply_nui=True)\n",
    "\n",
    "print(f\"Robust Model - Clean: {acc_nui_clean*100:.2f}% | NUI: {acc_nui_nui*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3980b",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" FINAL RESULTS (Caltech-256 Subset)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n Baseline Model (Trained on Clean Data):\")\n",
    "print(f\"   Clean Test Accuracy: {acc_clean_clean*100:.2f}%\")\n",
    "print(f\"   NUI Test Accuracy:   {acc_clean_nui*100:.2f}%\")\n",
    "print(f\"   Accuracy Drop:       {abs(acc_clean_clean - acc_clean_nui)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n Robust Model (NUI-Augmented Training):\")\n",
    "print(f\"   Clean Test Accuracy: {acc_nui_clean*100:.2f}%\")\n",
    "print(f\"   NUI Test Accuracy:   {acc_nui_nui*100:.2f}%\")\n",
    "print(f\"   Accuracy Drop:       {abs(acc_nui_clean - acc_nui_nui)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n Improvement Summary:\")\n",
    "drop_before = abs(acc_clean_clean - acc_clean_nui)*100\n",
    "drop_after = abs(acc_nui_clean - acc_nui_nui)*100\n",
    "improvement = drop_before - drop_after\n",
    "print(f\"   NUI Robustness Improvement: {improvement:.2f}%\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"   NUI-Augmented training successfully improved robustness!\")\n",
    "else:\n",
    "    print(\"    No significant improvement detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
